{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMI資料合併與特徵工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "from scipy.stats import kurtosis,skew#new\n",
    "from scipy.fftpack import fft#new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0805', '0806', '0807', '0808', '0809', '0810', '0811', '0812']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 這裡是存這個資料夾底下的資料夾並存成一個list因為我們將每天的資料都存成一個資料夾\n",
    "path='D:\\\\桌面\\\\before_Combine\\\\'\n",
    "dir_list = os.listdir(path)\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把 HMI狀態的json檔讀近來然後拆分塞進dataframe\n",
    "read_HMI_json = pd.read_json('HMI_data.json')\n",
    "get_Data_origin = read_HMI_json['data']\n",
    "get_Data_twice = get_Data_origin['history']\n",
    "df_HMI_json = DataFrame(get_Data_twice,columns = ['attrId','name','unit','values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 將拆好的dataframe再拆成三個dataframe，分別為機台狀態、溫度、電流。\n",
    "df_HMI_temperature = DataFrame(df_HMI_json.iloc[0,3])\n",
    "df_HMI_status = DataFrame(df_HMI_json.iloc[1,3])\n",
    "df_HMI_current = DataFrame(df_HMI_json.iloc[2,3])\n",
    "df_HMI_shape = df_HMI_status.shape\n",
    "\n",
    "#把時間戳換成datetime格式，並寫回去到原本的DF\n",
    "for timestamp in range(df_HMI_shape[0]):\n",
    "    df_HMI_status.iloc[timestamp,1] = datetime.datetime.fromtimestamp(round(df_HMI_status.iloc[timestamp,1]/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>reportTime</th>\n",
       "      <th>updateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-04 03:06:01</td>\n",
       "      <td>1596487537892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-04 03:06:31</td>\n",
       "      <td>1596487539900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-04 03:07:01</td>\n",
       "      <td>1596487539932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-04 03:07:31</td>\n",
       "      <td>1596487539977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-04 03:08:02</td>\n",
       "      <td>1596487540895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32264</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-15 07:57:32</td>\n",
       "      <td>1597449453163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32265</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-15 07:58:01</td>\n",
       "      <td>1597449482996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32266</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-15 07:58:31</td>\n",
       "      <td>1597449512818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32267</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-15 07:59:02</td>\n",
       "      <td>1597449543162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32268</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-15 07:59:32</td>\n",
       "      <td>1597449573196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32269 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      value           reportTime     updateTime\n",
       "0         0  2020-08-04 03:06:01  1596487537892\n",
       "1         0  2020-08-04 03:06:31  1596487539900\n",
       "2         0  2020-08-04 03:07:01  1596487539932\n",
       "3         0  2020-08-04 03:07:31  1596487539977\n",
       "4         0  2020-08-04 03:08:02  1596487540895\n",
       "...     ...                  ...            ...\n",
       "32264     0  2020-08-15 07:57:32  1597449453163\n",
       "32265     0  2020-08-15 07:58:01  1597449482996\n",
       "32266     0  2020-08-15 07:58:31  1597449512818\n",
       "32267     0  2020-08-15 07:59:02  1597449543162\n",
       "32268     0  2020-08-15 07:59:32  1597449573196\n",
       "\n",
       "[32269 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 檢查一下dataframe\n",
    "df_HMI_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 將HMI狀態的時間都抓出來做成一個list但只做到分鐘，秒都用00去替代\n",
    "datetime_list = []\n",
    "dirdaytime_list = []\n",
    "# 將HMI的每個資料的時間抓出來做日期格式化並存成list備用\n",
    "for datetime_format in range(df_HMI_shape[0]) :\n",
    "    dirdaytime_list.append(df_HMI_status.iloc[datetime_format,1].strftime('%m%d'))\n",
    "    datetime_list.append(df_HMI_status.iloc[datetime_format,1].strftime('%Y-%m-%d %H:%M')+':00')\n",
    "# 抓好之後將list中不重複的抓出來做成一個list備用\n",
    "datetime_list_unique = np.unique(datetime_list)\n",
    "dirdaytime_list_unique = np.unique(dirdaytime_list)\n",
    "# 將上面的HMI狀態時間list的shape存起來備用\n",
    "datetime_list_shape = len(datetime_list_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義一個function來抓時間列表\n",
    "# 輸入是一分鐘的string 例如:2020-08-05 00:01:00\n",
    "# txt_Time_list是上面HMI資料的所有格式化到小時的不重複資料\n",
    "def find_Index_wrong_position_list(correct_Time,txt_Time_list):\n",
    "    # 看HMI機台不重複時間有多少資料\n",
    "    def_len =  len(txt_Time_list)\n",
    "    # 開一個新的list準備儲存需要的時間\n",
    "    correct_list = []\n",
    "    # 將輸入進來的時間格式化\n",
    "    time_Format_c = datetime.datetime.strptime(correct_Time,\"%Y%m%d%H\")\n",
    "    time_Format_c = time_Format_c.strftime(\"%Y%m%d%H\")\n",
    "    print(time_Format_c)\n",
    "    # 這邊是為了讓程式更謹慎設定的count跟flag\n",
    "    flag = 0\n",
    "    check_count = 0\n",
    "    # for迴圈跑每一筆txt_Time_list時間\n",
    "    for def_line in range(def_len-1):\n",
    "        # 將txt_Time_list的時間資料做格式化\n",
    "        txt_time_check = datetime.datetime.strptime(str(txt_Time_list[def_line]),\"%Y-%m-%d %H:%M:%S\")\n",
    "        txt_time_check = txt_time_check.strftime(\"%Y%m%d%H\")\n",
    "        # 比對格式化完的資料是不是一樣，如果一樣就存入list 同時比對下一個時間是否也一樣\n",
    "        # 如果不一樣就直接回傳list\n",
    "        if txt_time_check == time_Format_c:\n",
    "            correct_list.append(txt_Time_list[def_line])\n",
    "            next_time = datetime.datetime.strptime(str(txt_Time_list[def_line+1]),\"%Y-%m-%d %H:%M:%S\")\n",
    "            next_time = next_time.strftime(\"%Y%m%d%H\")\n",
    "            if next_time != time_Format_c:\n",
    "                return correct_list\n",
    "                flag += 2\n",
    "        # 這一段用不到\n",
    "        elif txt_time_check != time_Format_c and flag==2:\n",
    "            return correct_list\n",
    "        # 這邊做檢查點\n",
    "        elif txt_time_check != time_Format_c and flag==0:\n",
    "            check_count+=1\n",
    "        else:\n",
    "            print('Error function find_Index_wrong_position_list() has a bug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 切分(新)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_Sec_df_Ver3(df_Cut_Sec_before):\n",
    "    # 將dataframe的長度存入一個變數備用\n",
    "    df_Shape_min = df_Cut_Sec_before.shape\n",
    "    # 把需要的資料欄位都開一個list\n",
    "    sec_Timestamp = []\n",
    "    sec_Z1_mean = []\n",
    "    sec_Z2_mean = []\n",
    "#   --------------------------------------------------------------------------------------\n",
    "    sec_Z1_max = []\n",
    "    sec_Z1_min = []\n",
    "    sec_Z2_max = []\n",
    "    sec_Z2_min = []\n",
    "#   --------------------------------------------------------------------------------------\n",
    "    sec_Z1_std = [] # 標準差\n",
    "    sec_Z1_skewness = [] # 偏度\n",
    "    sec_Z1_kurtosis = [] # 峰度\n",
    "    \n",
    "    sec_Z1_peakTopeak = [] # 波峰到波谷質\n",
    "    sec_Z1_RMS = [] # 平方平均數\n",
    "    sec_Z1_crestFactor = [] #峰質因素\n",
    "    sec_Z1_shapeFactor = [] #塑形工程\n",
    "    sec_Z1_impulseFactor = [] #脈衝工程\n",
    "    sec_Z1_marginFactor = [] #邊界工程\n",
    "\n",
    "    Spectrum_mean=[]#頻譜平均\n",
    "    Spectrum_std = []#頻譜標準差\n",
    "    Spectrum_mad = []#頻譜偏差\n",
    "    Spectrum_kur = []#頻譜峰度\n",
    "    Energy_signal = []#訊號能量\n",
    "#   --------------------------------------------------------------------------------------\n",
    "#   --------------------------------------------------------------------------------------\n",
    "    tmp_datatime = pd.to_datetime(df_Cut_Sec_before.iloc[0,0])\n",
    "#     print(type(tmp_datatime))\n",
    "#     print((tmp_datatime))\n",
    "#     now = (tmp_datatime+datetime.timedelta(seconds=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    sec_Timestamp.append(tmp_datatime)\n",
    "    df_sec_25 = pd.DataFrame()\n",
    "    df_sec_50 = pd.DataFrame()\n",
    "    df_sec_75 = pd.DataFrame()\n",
    "        \n",
    "    #df_sec的四分位數\n",
    "    df_sec25 = df_Cut_Sec_before.quantile(0.25)\n",
    "    df_sec75 = df_Cut_Sec_before.quantile(0.75)\n",
    "\n",
    "    df_sec_quartile25 = df_sec25['Z1']\n",
    "    df_sec_quartile75 = df_sec75['Z1']\n",
    "    #排序資料後用前25%的資料取最小值 最後25%取最大值 剩下的取平均值\n",
    "    df_sec_25 = df_sec_25.append(df_Cut_Sec_before[df_Cut_Sec_before['Z1']<=df_sec_quartile25],ignore_index=True)\n",
    "    df_sec_50 = df_sec_50.append(df_Cut_Sec_before[(df_Cut_Sec_before['Z1']>df_sec_quartile25) & (df_Cut_Sec_before['Z1']<df_sec_quartile75)],ignore_index=True)\n",
    "    df_sec_75 = df_sec_75.append(df_Cut_Sec_before[df_Cut_Sec_before['Z1']>=df_sec_quartile75],ignore_index=True)\n",
    "    #將做好最大最小平均的資料放進list\n",
    "    sec_Z1_max.append(np.max(df_sec_75['Z1']))\n",
    "    sec_Z1_min.append(np.min(df_sec_25['Z1']))\n",
    "    sec_Z1_mean.append(np.mean(df_sec_50['Z1']))\n",
    "    #將Z1的標準差 偏度 峰度 波峰到波谷值 放進list(這裡是直接呼叫函數直接運算後直接存入list)\n",
    "    sec_Z1_std.append(np.std(df_Cut_Sec_before['Z1']))\n",
    "    sec_Z1_skewness.append(skew(df_Cut_Sec_before['Z1']))\n",
    "    sec_Z1_kurtosis.append(kurtosis(df_Cut_Sec_before['Z1']))\n",
    "    sec_Z1_peakTopeak.append(np.ptp(df_Cut_Sec_before['Z1']))\n",
    "    #計算其他特徵工程需要的數字\n",
    "    RMS = math.sqrt(pow(np.mean(df_Cut_Sec_before['Z1']),2)+pow(np.std(df_Cut_Sec_before['Z1']),2))\n",
    "    crestFactor = np.max(np.abs(df_Cut_Sec_before['Z1'])/np.sqrt(np.mean(np.square(df_Cut_Sec_before['Z1']))))\n",
    "    shapeFactor = RMS/np.mean(np.abs(df_Cut_Sec_before['Z1']))\n",
    "    impulse = np.max(df_Cut_Sec_before['Z1'])/np.abs(np.mean(df_Cut_Sec_before['Z1']))\n",
    "    margin = np.max(df_Cut_Sec_before['Z1'])/pow(np.mean(np.abs(df_Cut_Sec_before['Z1'])),2)\n",
    "    #算完就放入list中\n",
    "    sec_Z1_RMS.append(RMS)\n",
    "    sec_Z1_crestFactor.append(crestFactor)\n",
    "    sec_Z1_shapeFactor.append(shapeFactor)\n",
    "    sec_Z1_impulseFactor.append(impulse)\n",
    "    sec_Z1_marginFactor.append(margin)\n",
    "    \n",
    "    df_Z1 = df_Cut_Sec_before['Z1']\n",
    "    df_Z1 = df_Z1.reset_index(drop=True)\n",
    "    #這一塊在做頻譜計算\n",
    "    Hz = df_Shape_min[0]/60\n",
    "    # 要修改的FFT\n",
    "    def FFT(x,Hz):\n",
    "        return np.sin(2*np.pi*Hz*x)\n",
    "    dataY = np.zeros(df_Shape_min[0])\n",
    "\n",
    "    for j in range(0,df_Shape_min[0]):\n",
    "        dataY[j] = FFT(df_Z1[j],Hz)\n",
    "    #算完就直接放入list\n",
    "    Spectrum = np.abs(fft(dataY))\n",
    "    Spectrum_mean.append(np.mean(Spectrum))\n",
    "    Spectrum_std.append(np.std(Spectrum))\n",
    "    Spectrum_mad.append(skew(Spectrum))\n",
    "    Spectrum_kur.append(kurtosis(Spectrum))\n",
    "    Energy_signal.append((np.mean(df_Z1)**2))\n",
    "#   --------------------------------------------------------------------------------------\n",
    "#     min_Z1_max = np.max(sec_Z1_max)\n",
    "#     min_Z1_min = np.min(sec_Z1_min)\n",
    "#     min_Z2_max = np.max(sec_Z2_max)\n",
    "#     min_Z2_min = np.min(sec_Z2_min)\n",
    "#   --------------------------------------------------------------------------------------\n",
    "    # 開一個新的dataframe 將上面做的特徵工程list存入dataframe\n",
    "    sec_point = pd.DataFrame()\n",
    "    sec_point['Timestamp'] = sec_Timestamp\n",
    "    sec_point['Z1_mean'] = sec_Z1_mean\n",
    "    sec_point['Z1_max'] = sec_Z1_max\n",
    "    sec_point['Z1_min'] = sec_Z1_min\n",
    "    sec_point['Z1_std'] = sec_Z1_std\n",
    "    sec_point['Z1_skew'] = sec_Z1_skewness\n",
    "    sec_point['Z1_kurtosis'] = sec_Z1_kurtosis\n",
    "    sec_point['Z1_peakTopeak'] = sec_Z1_peakTopeak\n",
    "    sec_point['Z1_RMS'] = sec_Z1_RMS\n",
    "    sec_point['Z1_crestFactor'] = sec_Z1_crestFactor\n",
    "    sec_point['Z1_shapeFactor'] = sec_Z1_shapeFactor\n",
    "    sec_point['Z1_impulseFactor'] = sec_Z1_impulseFactor\n",
    "    sec_point['Z1_marginFactor'] = sec_Z1_marginFactor\n",
    "    sec_point['energy_Signal'] = Energy_signal\n",
    "    sec_point['spectrum_Mean'] = Spectrum_mean\n",
    "    sec_point['spectrum_Std'] = Spectrum_std\n",
    "    sec_point['spectrum_Skew'] = Spectrum_mad\n",
    "    sec_point['spectrum_Kur'] = Spectrum_kur\n",
    "#     sec_point['spectrum'] = Spectrum\n",
    "    # 將dataframe回傳\n",
    "    return sec_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020080500\n",
      "2020080500_after.json 60 2\n",
      "2020080501\n",
      "2020080501_after.json 60 2\n",
      "2020080502\n",
      "2020080502_after.json 60 2\n",
      "2020080503\n",
      "2020080503_after.json 60 2\n",
      "2020080504\n",
      "2020080504_after.json 60 2\n",
      "2020080505\n",
      "2020080505_after.json 60 2\n",
      "2020080506\n",
      "2020080506_after.json 60 2\n",
      "2020080507\n",
      "2020080507_after.json 60 2\n",
      "2020080508\n",
      "2020080508_after.json 60 2\n",
      "2020080509\n",
      "2020080509_after.json 60 2\n",
      "2020080510\n",
      "2020080510_after.json 60 2\n",
      "2020080511\n",
      "2020080511_after.json 60 2\n",
      "2020080512\n",
      "4015\n",
      "index_count = 3\n",
      "2020080512_after.json 60 2\n",
      "2020080513\n",
      "4184\n",
      "index_count = 3\n",
      "2020080513_after.json 60 2\n",
      "2020080514\n",
      "2020080514_after.json 60 2\n",
      "2020080515\n",
      "2020080515_after.json 60 2\n",
      "2020080516\n",
      "2020080516_after.json 60 2\n",
      "2020080517\n",
      "2020080517_after.json 60 2\n",
      "2020080518\n",
      "2020080518_after.json 60 2\n",
      "2020080519\n",
      "2020080519_after.json 60 2\n",
      "2020080520\n",
      "2020080520_after.json 60 2\n",
      "2020080521\n",
      "2020080521_after.json 60 2\n",
      "2020080522\n",
      "2020080522_after.json 60 2\n",
      "2020080523\n",
      "2020080523_after.json 60 2\n",
      "2020080600\n",
      "2020080600_after.json 60 2\n",
      "2020080601\n",
      "2020080601_after.json 60 2\n",
      "2020080602\n",
      "2020080602_after.json 60 2\n",
      "2020080603\n",
      "2020080603_after.json 60 2\n",
      "2020080604\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-02f89d70e838>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m                     \u001b[0mindex_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_sec_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                     \u001b[1;31m# 然後將新的dataframe放進特徵工程用的function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                     \u001b[0mdf_60_sec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcut_Sec_df_Ver3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_sec_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Error - 特徵工程function '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-554015255d6b>\u001b[0m in \u001b[0;36mcut_Sec_df_Ver3\u001b[1;34m(df_Cut_Sec_before)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_Shape_min\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mdataY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFFT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_Z1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mHz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[1;31m#算完就直接放入list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mSpectrum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4377\u001b[0m         \u001b[1;31m# use this, e.g. DatetimeIndex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m         \u001b[1;31m# Things like `Series._get_value` (via .at) pass the EA directly here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4379\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4380\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExtensionArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4381\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36mextract_array\u001b[1;34m(obj, extract_numpy)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mextract_numpy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCPandasArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36mto_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[1;31m# Additional Methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mna_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for迴圈跑每個資料\n",
    "for dirdaytime_list_unique in dir_list:\n",
    "    # 先創一個新的dataframe，這是用來儲存要輸出的資料\n",
    "    csv_Dataframe = pd.DataFrame()\n",
    "    \n",
    "#     path='D:\\\\福壽\\\\製粒機\\\\製粒機(8月)\\\\'\n",
    "    path='D:\\\\桌面\\\\before_Combine\\\\'\n",
    "    # 用上面的資料夾加上路徑直接抓到那一天資料夾底下的資料\n",
    "    file_list = os.listdir(path+dirdaytime_list_unique)\n",
    "    # 抓小時\n",
    "    # 資料夾內的每個檔案都跑一遍\n",
    "    for read_File_list in file_list :\n",
    "        # 將讀到的資料存成dataframe\n",
    "        df_Clean_json = pd.read_json(path+dirdaytime_list_unique+'\\\\'+read_File_list)\n",
    "#         txt_Time_index=999999999\n",
    "        count_minute = 0\n",
    "        # 將檔名多餘的字元切除，把檔名中的時間當作索引然後帶入寫好的function後會得到這個小時在HMI資料中所有的時間列表\n",
    "        file_list_time = read_File_list.split('_')\n",
    "        # datetime_list_unique是上面在處理HMI資料時做的\n",
    "        time_After_check = find_Index_wrong_position_list(file_list_time[0],datetime_list_unique)\n",
    "        # 如果time_After_check中沒有任何資料代表這個小時的檔案中沒有任何一個時間是在HMI資料的範圍內\n",
    "        if time_After_check == None:\n",
    "            print('這小時沒有任何資料喔~啾咪 0.<')\n",
    "        else:\n",
    "            # 將time_After_check的每個時間都做for迴圈處理(每分鐘都要做處理)\n",
    "            for every_Minute_in_txt in time_After_check:\n",
    "                # 將dataframe中時間等於for迴圈讀到的那一分鐘的所有資料存入另一個dataframe\n",
    "                df_sec_1 = df_Clean_json.loc[df_Clean_json['Timestamp']== str(every_Minute_in_txt)]\n",
    "                try:\n",
    "                    # 確認這一分鐘在HMI中的資料有幾筆\n",
    "                    index_count = datetime_list.count(str(df_sec_1.iloc[0,0]))\n",
    "                    # 然後將新的dataframe放進特徵工程用的function\n",
    "                    df_60_sec = cut_Sec_df_Ver3(df_sec_1)\n",
    "                except Exception as e:\n",
    "                    print('Error - 特徵工程function ',e)\n",
    "                count_minute+=1\n",
    "                # 設定if條件，正常狀態的HMI一分鐘會有兩個資料，但有些會有3個，所以這邊做檢查。\n",
    "                if index_count == 3:\n",
    "                    try:\n",
    "                        # 這邊是用df_sec_1的這一分鐘當作索引去找HMI機台狀態中這一分鐘的索引值\n",
    "                        txt_Time_index = datetime_list.index(str(df_sec_1.iloc[0,0]))\n",
    "                        print(txt_Time_index)\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        # 在dataframe中開新的欄位準備合併HMI機台資料\n",
    "                        df_60_sec['machine_Status_avg']=''\n",
    "                        df_60_sec['Temperature_avg']=''\n",
    "                        df_60_sec['Current_avg']=''\n",
    "                        df_60_sec['Current_max']=''\n",
    "                        # 將HMI機台狀態的資料都存成list\n",
    "                        machine_Status_list = [float(df_HMI_status.iloc[txt_Time_index,0]),float(df_HMI_status.iloc[txt_Time_index+1,0]),float(df_HMI_status.iloc[txt_Time_index+2,0])]\n",
    "                        Temperature_list = [float(df_HMI_temperature.iloc[txt_Time_index,0]),float(df_HMI_temperature.iloc[txt_Time_index+1,0]),float(df_HMI_temperature.iloc[txt_Time_index+2,0])]\n",
    "                        Current = [float(df_HMI_current.iloc[txt_Time_index,0]),float(df_HMI_current.iloc[txt_Time_index+1,0]),float(df_HMI_current.iloc[txt_Time_index+2,0])]\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        # 將存成list的HMI機台狀態做 max跟平均 然後存在dataframe後面\n",
    "                        df_60_sec.iloc[:,18] = np.max(machine_Status_list)\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        df_60_sec.iloc[:,19] = np.mean(Temperature_list)\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        df_60_sec.iloc[:,20] = np.mean(Current)\n",
    "                        df_60_sec.iloc[:,21] = np.max(Current)\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        # 將寫好的dataframe併入上面開的空dataframe，等到換資料夾時會直接輸出成csv再清空。\n",
    "                        csv_Dataframe = csv_Dataframe.append(df_60_sec,ignore_index=True)\n",
    "                    except Exception as q:\n",
    "                        print('index_count = 3 , index_count判定有bug: ',q)\n",
    "#                     txt_Time_index = datetime_list.index(df_Clean_json['Timestamp'].iloc[0])\n",
    "                    #----------------------------------------------------------------------------\n",
    "                    print('index_count = 3')\n",
    "                # 下面的if條件的code都跟上面一樣，只差在HMI有幾個值要放進list\n",
    "                elif index_count == 2:\n",
    "                    try:\n",
    "                        txt_Time_index = datetime_list.index(str(df_sec_1.iloc[0,0]))\n",
    "#                         print(str(df_sec_1.iloc[0,0]),txt_Time_index)\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        df_60_sec['machine_Status_avg']=''\n",
    "                        df_60_sec['Temperature_avg']=''\n",
    "                        df_60_sec['Current_avg']=''\n",
    "                        df_60_sec['Current_max']=''\n",
    "                        machine_Status_list = [float(df_HMI_status.iloc[txt_Time_index,0]),float(df_HMI_status.iloc[txt_Time_index+1,0])]\n",
    "                        Temperature_list = [float(df_HMI_temperature.iloc[txt_Time_index,0]),float(df_HMI_temperature.iloc[txt_Time_index+1,0])]\n",
    "                        Current = [float(df_HMI_current.iloc[txt_Time_index,0]),float(df_HMI_current.iloc[txt_Time_index+1,0])]\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        df_60_sec.iloc[:,18] = np.max(machine_Status_list)\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        df_60_sec.iloc[:,19] = np.mean(Temperature_list)\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        df_60_sec.iloc[:,20] = np.mean(Current)\n",
    "                        df_60_sec.iloc[:,21] = np.max(Current)\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        csv_Dataframe = csv_Dataframe.append(df_60_sec,ignore_index=True)\n",
    "                    except Exception as q:\n",
    "                        print('index_count = 2 , 判定有bug: ',q)\n",
    "                elif index_count == 1:\n",
    "                    try:\n",
    "                        txt_Time_index = datetime_list.index(str(df_sec_1.iloc[0,0]))\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        df_60_sec['machine_Status_avg']=''\n",
    "                        df_60_sec['Temperature_avg']=''\n",
    "                        df_60_sec['Current_avg']=''\n",
    "                        df_60_sec['Current_max']=''\n",
    "                        machine_Status_list = [float(df_HMI_status.iloc[txt_Time_index,0])]\n",
    "                        Temperature_list = [float(df_HMI_temperature.iloc[txt_Time_index,0])]\n",
    "                        Current = [float(df_HMI_current.iloc[txt_Time_index,0])]\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        df_60_sec.iloc[:,18] = machine_Status_list\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        df_60_sec.iloc[:,19] = Temperature_list\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        df_60_sec.iloc[:,20] = Current\n",
    "                        df_60_sec.iloc[:,21] = Current\n",
    "                        #----------------------------------------------------------------------------\n",
    "                        csv_Dataframe = csv_Dataframe.append(df_60_sec,ignore_index=True)\n",
    "                    except Exception as q:\n",
    "                        print('index_count = 1 , 判定有bug: ',q)\n",
    "                        #----------------------------------------------------------------------------\n",
    "                else:\n",
    "                    print('Error 其他:',df_sec_1.iloc[0,0],'index_count:',index_count)\n",
    "            # 提示進度\n",
    "            print(read_File_list,count_minute,index_count)\n",
    "    # 寫入csv\n",
    "    csv_Dataframe.to_csv('D:\\\\桌面\\\\train_Data\\\\json_Combine_txt_ToCSV_'+dirdaytime_list_unique+'_V3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_After_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in datetime_list_unique:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
